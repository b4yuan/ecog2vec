{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecog2vec.data_generator import NeuralDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "efc401 = NeuralDataGenerator('/NWB/EFC401', 'EFC401')\n",
    "efc401.bad_electrodes = [1,2,63,64,65,127,143,193,194,195,196,235,239,243,252,254,255,256]\n",
    "efc401.bad_electrodes = [x - 1 for x in efc401.bad_electrodes]\n",
    "efc401.good_electrodes = [x for x in efc401.good_electrodes if x not in efc401.bad_electrodes]\n",
    "\n",
    "# import random\n",
    "\n",
    "# efc400 = NeuralDataGenerator('/NWB/EFC400', 'EFC400')\n",
    "# efc400.bad_electrodes = [1, 2, 33, 50, 54, 64, 128, 129, 193, 194, 256]\n",
    "\n",
    "# available_numbers = [num for num in range(1, 257) if num not in efc400.bad_electrodes]\n",
    "# random_numbers = random.sample(available_numbers, 7)\n",
    "# efc400.bad_electrodes = efc400.bad_electrodes + random_numbers\n",
    "\n",
    "# efc400.bad_electrodes = [x - 1 for x in efc400.bad_electrodes]\n",
    "# efc400.good_electrodes = [x for x in efc400.good_electrodes if x not in efc400.bad_electrodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created or already exists: /home/bayuan/Documents/fall23/ecog2vec/wav2vec_inputs\n",
      "Directory created or already exists: /home/bayuan/Documents/fall23/ecog2vec/wav2vec_inputs/chopped_sentence\n",
      "Directory created or already exists: /home/bayuan/Documents/fall23/ecog2vec/wav2vec_inputs/sentence\n",
      "Directory created or already exists: /home/bayuan/Documents/fall23/ecog2vec/wav2vec_inputs/chopped_recording\n",
      "Directory created or already exists: /home/bayuan/Documents/fall23/ecog2vec/wav2vec_inputs/full_recording\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.6.0 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.3.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.6.0 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.3.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.6.0 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.3.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.6.0 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.3.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.6.0 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.3.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.6.0 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.3.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.6.0 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.3.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.6.0 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.3.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.6.0 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.3.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.6.0 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.3.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.6.0 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.3.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.6.0 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.3.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.6.0 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.3.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.6.0 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.3.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.6.0 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.3.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.6.0 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.3.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.6.0 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.3.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.6.0 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.3.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Save clipped data for training,\n",
    "# save unclipped data to extract features from,\n",
    "# save entire recording as chunks for training,\n",
    "# save entire reocording to extract features from\n",
    "parent_dir = '/home/bayuan/Documents/fall23/ecog2vec/wav2vec_inputs'\n",
    "\n",
    "chopped_sentence_dir = '/home/bayuan/Documents/fall23/ecog2vec/wav2vec_inputs/chopped_sentence'\n",
    "sentence_dir = '/home/bayuan/Documents/fall23/ecog2vec/wav2vec_inputs/sentence'\n",
    "chopped_recording_dir = '/home/bayuan/Documents/fall23/ecog2vec/wav2vec_inputs/chopped_recording'\n",
    "full_recording_dir = '/home/bayuan/Documents/fall23/ecog2vec/wav2vec_inputs/full_recording'\n",
    "\n",
    "for directory in [parent_dir, chopped_sentence_dir, sentence_dir, chopped_recording_dir, full_recording_dir]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"Directory created or already exists: {directory}\")\n",
    "\n",
    "chunk_length = 200000\n",
    "\n",
    "block_list = []\n",
    "\n",
    "# 'write_raw_data', but really it's filtered to the high\n",
    "# gamma range and the analytic amplitude is calculated\n",
    "efc401.write_raw_data(\n",
    "    # chopped_sentence_dir=chopped_sentence_dir,\n",
    "    # sentence_dir=sentence_dir,\n",
    "    full_recording_dir=full_recording_dir,\n",
    "    chopped_recording_dir=chopped_recording_dir,\n",
    "    chunk_length=chunk_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train and extract `wav2vec` features\n",
    "\n",
    "Split into test/valid and train.\n",
    "\n",
    "Strides should downsample by ~30x; `wav2vec` takes 16kHz inputs and our raw data is at 3kHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed from facebookresearch/fairseq with minor modifications\n",
    "\n",
    "!python3 /home/bayuan/Documents/fall23/fairseq/examples/wav2vec/wav2vec_manifest.py \\\n",
    "    /home/bayuan/Documents/fall23/ecog2vec/wav2vec_inputs/chopped_recording \\\n",
    "  --dest /home/bayuan/Documents/fall23/ecog2vec/manifest \\\n",
    "  --ext wav \\\n",
    "  --valid-percent 0.1 \\\n",
    "  --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/argparse.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-26 15:05:04.348678: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-26 15:05:04.348716: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-26 15:05:04.349895: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-26 15:05:04.354943: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
      "    from tensorboard.compat import notf  # noqa: F401\n",
      "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/tensorboard/compat/__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bayuan/Documents/fall23/fairseq/train.py\", line 10, in <module>\n",
      "    from fairseq_cli.train import cli_main\n",
      "  File \"/home/bayuan/Documents/fall23/fairseq/fairseq_cli/train.py\", line 30, in <module>\n",
      "    from fairseq import checkpoint_utils, options, quantization_utils, tasks, utils\n",
      "  File \"/home/bayuan/Documents/fall23/fairseq/fairseq/__init__.py\", line 21, in <module>\n",
      "    from fairseq.logging import meters, metrics, progress_bar  # noqa\n",
      "  File \"/home/bayuan/Documents/fall23/fairseq/fairseq/logging/progress_bar.py\", line 407, in <module>\n",
      "    from torch.utils.tensorboard import SummaryWriter\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py\", line 12, in <module>\n",
      "    from .writer import FileWriter, SummaryWriter  # noqa: F401\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/torch/utils/tensorboard/writer.py\", line 16, in <module>\n",
      "    from ._embedding import get_embedding_info, make_mat, make_sprite, make_tsv, write_pbtxt\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/torch/utils/tensorboard/_embedding.py\", line 9, in <module>\n",
      "    _HAS_GFILE_JOIN = hasattr(tf.io.gfile, \"join\")\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/tensorboard/lazy.py\", line 65, in __getattr__\n",
      "    return getattr(load_once(self), attr_name)\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/tensorboard/lazy.py\", line 97, in wrapper\n",
      "    cache[arg] = f(arg)\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/tensorboard/lazy.py\", line 50, in load_once\n",
      "    module = load_fn()\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/tensorboard/compat/__init__.py\", line 45, in tf\n",
      "    import tensorflow\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/tensorflow/__init__.py\", line 48, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 11, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import distribute\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/distribute/__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__.distribute import combinations\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/distribute/combinations/__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.distribute.combinations import env # line: 456\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/tensorflow/python/distribute/combinations.py\", line 33, in <module>\n",
      "    from tensorflow.python.distribute import collective_all_reduce_strategy\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py\", line 25, in <module>\n",
      "    from tensorflow.python.distribute import cross_device_ops as cross_device_ops_lib\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/tensorflow/python/distribute/cross_device_ops.py\", line 28, in <module>\n",
      "    from tensorflow.python.distribute import cross_device_utils\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/tensorflow/python/distribute/cross_device_utils.py\", line 22, in <module>\n",
      "    from tensorflow.python.distribute import values as value_lib\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/tensorflow/python/distribute/values.py\", line 23, in <module>\n",
      "    from tensorflow.python.distribute import distribute_lib\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 206, in <module>\n",
      "    from tensorflow.python.data.ops import dataset_ops\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/tensorflow/python/data/__init__.py\", line 21, in <module>\n",
      "    from tensorflow.python.data import experimental\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/tensorflow/python/data/experimental/__init__.py\", line 98, in <module>\n",
      "    from tensorflow.python.data.experimental import service\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/tensorflow/python/data/experimental/service/__init__.py\", line 419, in <module>\n",
      "    from tensorflow.python.data.experimental.ops.data_service_ops import distribute\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/tensorflow/python/data/experimental/ops/data_service_ops.py\", line 25, in <module>\n",
      "    from tensorflow.python.data.ops import dataset_ops\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 33, in <module>\n",
      "    from tensorflow.python.data.ops import iterator_ops\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 25, in <module>\n",
      "    from tensorflow.python.data.ops import options as options_lib\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/tensorflow/python/data/ops/options.py\", line 89, in <module>\n",
      "    class AutoShardPolicy(enum.IntEnum):\n",
      "  File \"/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/enum.py\", line 244, in __new__\n",
      "    if not any(m in member_type.__dict__ for m in methods):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# --log-keys \"[\"prob_perplexity\",\"code_perplexity\",\"temp\"]\" \n",
    "\n",
    "!python3 -c 'import argparse; print(argparse.__file__)'\n",
    "!python /home/bayuan/Documents/fall23/fairseq/train.py /home/bayuan/Documents/fall23/ecog2vec/manifest \\\n",
    "    --save-dir /home/bayuan/Documents/fall23/ecog2vec/model \\\n",
    "    --num-workers 6 --fp16 --max-update 400000 --infonce \\\n",
    "    --save-interval 1 --no-epoch-checkpoints --arch wav2vec --task audio_pretraining --min-lr 1e-06 --stop-min-lr 1e-09 \\\n",
    "    --optimizer adam --lr 1e-05 --lr-scheduler cosine \\\n",
    "    --conv-feature-layers \"[(512, 8, 30)]\" \\\n",
    "    --conv-aggregator-layers \"[(512, 12, 1)]\" \\\n",
    "    --activation gelu --offset auto --skip-connections-agg --residual-scale 0.5 \\\n",
    "    --vq-type gumbel --vq-groups 2 --vq-depth 2 \\\n",
    "    --combine-groups --vq-vars 320 --vq-temp \"(2,0.5,0.999995)\" --prediction-steps 12 --warmup-updates 1000 \\\n",
    "    --warmup-init-lr 1e-07 --criterion wav2vec --num-negatives 10 --max-sample-size 200000 \\\n",
    "    --max-tokens 300000 --cross-sample-negatives 0 --update-freq 1 --seed 2 --skip-invalid-size-inputs-valid-test \\\n",
    "    --tensorboard-logdir /home/bayuan/Documents/fall23/ecog2vec/runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract $c$ embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract entire recording, then chop up into sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-24 09:26:57.079053: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-24 09:26:57.079088: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-24 09:26:57.080273: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-24 09:26:57.085988: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-24 09:26:57.633080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/bayuan/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Wav2Vec2Model' object has no attribute 'feature_aggregator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 32\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# print(wav_input_16khz.shape)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# print(sr, wav_input_16khz.shape)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m z \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfeature_extractor(wav_input_16khz)\n\u001b[0;32m---> 32\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_aggregator\u001b[49m(z)\n\u001b[1;32m     34\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(c, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/bayuan/Documents/fall23/ecog2vec/wav2vec_outputs/latent_sentence/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ecog2txt/lib/python3.9/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Wav2Vec2Model' object has no attribute 'feature_aggregator'"
     ]
    }
   ],
   "source": [
    "# Borrowed from facebookresearch/fairseq with minor modifications\n",
    "\n",
    "import torch\n",
    "import fairseq\n",
    "# from scipy.io import wavfile\n",
    "import os\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "cp_path = '/home/bayuan/Documents/fall23/ecog2vec/notebooks/outputs/2023-12-20/15-32-57/checkpoints/checkpoint_best.pt'#'/path/to/wav2vec.pt'\n",
    "model, cfg, task = fairseq.checkpoint_utils.load_model_ensemble_and_task([cp_path])\n",
    "model = model[0]\n",
    "model.eval()\n",
    "\n",
    "dir_path = '/home/bayuan/Documents/fall23/ecog2vec/wav2vec_inputs/full_recording'\n",
    "\n",
    "for file in os.listdir(dir_path):\n",
    "\n",
    "    wav_path = str(os.path.join(dir_path, file))\n",
    "\n",
    "    wav_input_16khz, sr = sf.read(wav_path)\n",
    "    print(type(wav_input_16khz))\n",
    "    # \n",
    "    wav_input_16khz = wav_input_16khz.T\n",
    "    wav_input_16khz = wav_input_16khz.reshape(1, 238, -1)#wav_input_16khz[np.newaxis, :, :] # change to 256; 480\n",
    "\n",
    "    wav_input_16khz = torch.from_numpy(wav_input_16khz).to(torch.float)\n",
    "    # print(wav_input_16khz.shape)\n",
    "\n",
    "    # print(sr, wav_input_16khz.shape)\n",
    "    z = model.feature_extractor(wav_input_16khz)\n",
    "    c = model.feature_aggregator(z)\n",
    "    \n",
    "    torch.save(c, f\"/home/bayuan/Documents/fall23/ecog2vec/wav2vec_outputs/latent_sentence/{file}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecog2txt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
